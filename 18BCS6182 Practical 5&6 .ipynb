{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handwritten digit recognition using SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all necessary libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import file and reading few lines\n",
    "numbers = pd.read_csv(r'C:/Users/SV Reddy/Downloads/train.csv',encoding = \"latin\")\n",
    "numbers.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data understanding and exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking datatype\n",
    "numbers.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the columns are of dtype - int64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers.describe(percentiles = [0.05,0.10,0.25,0.50,0.75,0.90,0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for null values\n",
    "round(100*(numbers.isnull().sum()/(len(numbers.index))),2).sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no null values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column- `Label`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us check unique entries of label column\n",
    "np.unique(numbers['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualising the column - label\n",
    "sns.countplot(numbers['label'],palette = 'icefire')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let us examine few `pixels`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.value_counts(numbers.values.ravel()).sort_index()\n",
    "N = len(y)\n",
    "x = range(N)\n",
    "width =0.9\n",
    "plt.figure(figsize=[8,8])\n",
    "plt.bar(x, y, width, color=\"blue\")\n",
    "plt.title('Pixel Value Frequency (Log Scale)')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Pixel Value (0-255)')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "sns.distplot(numbers['pixel656'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "sns.distplot(numbers['pixel684'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `label` vs `pixel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='label', y='pixel683', data=numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='label', y='pixel572', data=numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let us visualize few numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one = numbers.iloc[2, 1:]\n",
    "one = one.values.reshape(28,28)\n",
    "plt.imshow(one)\n",
    "plt.title(\"Digit 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero = numbers.iloc[1, 1:]\n",
    "zero = zero.values.reshape(28,28)\n",
    "plt.imshow(zero)\n",
    "plt.title(\"Digit 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nine = numbers.iloc[11, 1:]\n",
    "nine = nine.values.reshape(28,28)\n",
    "plt.imshow(nine)\n",
    "plt.title(\"Digit 9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let us check heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "sns.heatmap(data=numbers.corr(),annot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost all nearby pixel values are correlated, which is expected as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average feature values\n",
    "pd.set_option('display.max_rows', 999)\n",
    "round(numbers.drop('label', axis=1).mean(), 2).sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that average varies between 140 to 0. It is better to scale them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting into X and y\n",
    "X = numbers.drop(\"label\", axis = 1)\n",
    "y = numbers['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the features\n",
    "X_scaled = scale(X)\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, train_size=0.2,test_size = 0.8, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_train shape:',X_train.shape)\n",
    "print('y_train shape:',y_train.shape)\n",
    "print('X_test shape:',X_test.shape)\n",
    "print('y_test shape:',y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Let us first try - `Linear` model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear model\n",
    "model_linear = SVC(kernel='linear')\n",
    "model_linear.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = model_linear.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix and accuracy, precision, recall\n",
    "\n",
    "# accuracy\n",
    "print(\"accuracy:\", metrics.accuracy_score(y_true=y_test, y_pred=y_pred), \"\\n\")\n",
    "\n",
    "# cm\n",
    "print(metrics.confusion_matrix(y_true=y_test, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#precision, recall and f1-score\n",
    "scores=metrics.classification_report(y_test, y_pred, labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear model gives approx. 91.31% accuracy. Let's look at a non-linear model with randomly chosen hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try `Non- linear` models:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. `Poly` kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-linear model\n",
    "# using poly kernel, C=1, default value of gamma\n",
    "\n",
    "# model\n",
    "non_linear_model_poly = SVC(kernel='poly')\n",
    "\n",
    "# fit\n",
    "non_linear_model_poly.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = non_linear_model_poly.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix and accuracy, precision, recall\n",
    "\n",
    "# accuracy\n",
    "print(\"accuracy:\", metrics.accuracy_score(y_true=y_test, y_pred=y_pred), \"\\n\")\n",
    "\n",
    "# cm\n",
    "print(metrics.confusion_matrix(y_true=y_test, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy dropped to 87.12%, so obviously no point in going with polynomial. Let us try 'rbf'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. `rbf` kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-linear model\n",
    "# using rbf kernel, C=1, default value of gamma\n",
    "\n",
    "# model\n",
    "non_linear_model = SVC(kernel='rbf')\n",
    "\n",
    "# fit\n",
    "non_linear_model.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = non_linear_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix and accuracy, precision, recall\n",
    "\n",
    "# accuracy\n",
    "print(\"accuracy:\", metrics.accuracy_score(y_true=y_test, y_pred=y_pred), \"\\n\")\n",
    "\n",
    "# cm\n",
    "print(metrics.confusion_matrix(y_true=y_test, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#precision, recall and f1-score\n",
    "scores=metrics.classification_report(y_test, y_pred, labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we clearly see that the non-linear `rbf` model gives approx. 94% accuracy. And most of the precision is above 90%.Thus, going forward, let's choose hyperparameters corresponding to non-linear `rbf` models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search: Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a KFold object with 5 splits \n",
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 101)\n",
    "\n",
    "# specify range of hyperparameters\n",
    "# Set the parameters by cross-validation\n",
    "hyper_params = [ {'gamma': [0.01, 0.001,0.0001],\n",
    "                     'C': [1, 10, 100]}]\n",
    "\n",
    "\n",
    "# specify model\n",
    "model = SVC(kernel=\"rbf\")\n",
    "\n",
    "# set up GridSearchCV()\n",
    "model_cv = GridSearchCV(estimator = model, \n",
    "                        param_grid = hyper_params, \n",
    "                        scoring= 'accuracy', \n",
    "                        cv = folds, \n",
    "                        verbose = 1,\n",
    "                        return_train_score=True,n_jobs = -1)      \n",
    "\n",
    "# fit the model\n",
    "model_cv.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv results\n",
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting C to numeric type for plotting on x-axis\n",
    "cv_results['param_C'] = cv_results['param_C'].astype('int')\n",
    "\n",
    "# # plotting\n",
    "plt.figure(figsize=(20,7))\n",
    "\n",
    "# subplot 1/3\n",
    "plt.subplot(131)\n",
    "gamma_01 = cv_results[cv_results['param_gamma']==0.01]\n",
    "\n",
    "plt.plot(gamma_01[\"param_C\"], gamma_01[\"mean_test_score\"])\n",
    "plt.plot(gamma_01[\"param_C\"], gamma_01[\"mean_train_score\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Gamma=0.01\")\n",
    "plt.ylim([0.50, 1.1])\n",
    "plt.legend(['test accuracy', 'train accuracy'], loc='upper left')\n",
    "plt.xscale('log')\n",
    "\n",
    "# subplot 2/3\n",
    "plt.subplot(132)\n",
    "gamma_001 = cv_results[cv_results['param_gamma']==0.001]\n",
    "\n",
    "plt.plot(gamma_001[\"param_C\"], gamma_001[\"mean_test_score\"])\n",
    "plt.plot(gamma_001[\"param_C\"], gamma_001[\"mean_train_score\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Gamma=0.001\")\n",
    "plt.ylim([0.50, 1.1])\n",
    "plt.legend(['test accuracy', 'train accuracy'], loc='upper left')\n",
    "plt.xscale('log')\n",
    "\n",
    "\n",
    "# subplot 3/3\n",
    "plt.subplot(133)\n",
    "gamma_0001 = cv_results[cv_results['param_gamma']==0.0001]\n",
    "\n",
    "plt.plot(gamma_0001[\"param_C\"], gamma_0001[\"mean_test_score\"])\n",
    "plt.plot(gamma_0001[\"param_C\"], gamma_0001[\"mean_train_score\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Gamma=0.0001\")\n",
    "plt.ylim([0.50, 1.1])\n",
    "plt.legend(['test accuracy', 'train accuracy'], loc='upper left')\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing the optimal accuracy score and hyperparameters\n",
    "best_score = model_cv.best_score_\n",
    "best_hyperparams = model_cv.best_params_\n",
    "\n",
    "print(\"The best test score is {0} corresponding to hyperparameters {1}\".format(best_score, best_hyperparams))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us take the best value ({'C': 10, 'gamma': 0.001}) as suggested by the sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building and Evaluating the Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model with optimal hyperparameters\n",
    "\n",
    "# model\n",
    "model = SVC(C=10, gamma=0.001, kernel=\"rbf\")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# metrics\n",
    "print(\"accuracy\", metrics.accuracy_score(y_test, y_pred), \"\\n\")\n",
    "print(metrics.confusion_matrix(y_test, y_pred), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# different class-wise accuracy - #precision, recall and f1-score\n",
    "scores=metrics.classification_report(y_test, y_pred, labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that with hyperparameter - C = 10 and gamma = 0.001, we see overall accuracy of the model is 95% and also precision for each label is above 94%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us visualize our final model on unseen training dataset\n",
    "\n",
    "df = np.random.randint(1,y_pred.shape[0]+1,5)\n",
    "\n",
    "plt.figure(figsize=(16,4))\n",
    "for i,j in enumerate(df):\n",
    "    plt.subplot(150+i+1)\n",
    "    d = X_test[j].reshape(28,28)\n",
    "    plt.title(f'Predicted Label: {y_pred[j]}')\n",
    "    plt.imshow(d)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let us use our final model on test data (test.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import file and reading few lines\n",
    "test_df = pd.read_csv(r'C:/Users/SV Reddy/Downloads/test.csv',encoding = \"latin\")\n",
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the features\n",
    "test_scaled = scale(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.predict\n",
    "test_predict = model.predict(test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the distribution of prediction\n",
    "a = {'ImageId': np.arange(1,test_predict.shape[0]+1), 'Label': test_predict}\n",
    "data_to_export = pd.DataFrame(a)\n",
    "sns.countplot(data_to_export['Label'], palette = 'icefire')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us visualize few of predicted test numbers\n",
    "\n",
    "df = np.random.randint(1,test_predict.shape[0]+1,5)\n",
    "\n",
    "plt.figure(figsize=(16,4))\n",
    "for i,j in enumerate(df):\n",
    "    plt.subplot(150+i+1)\n",
    "    d = test_scaled[j].reshape(28,28)\n",
    "    plt.title(f'Predicted Label: {test_predict[j]}')\n",
    "    plt.imshow(d)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
